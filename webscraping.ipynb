{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "def scrape_product_listing(url, num_pages):\n",
        "    data = []\n",
        "\n",
        "    for page in range(1, num_pages + 1):\n",
        "        page_url = url + f'&page={page}'\n",
        "        response = requests.get(page_url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        products = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
        "\n",
        "        for product in products:\n",
        "            product_url = product.find('a', {'class': 'a-link-normal'})['href']\n",
        "            product_name = product.find('span', {'class': 'a-text-normal'}).text.strip()\n",
        "\n",
        "            product_price = product.find('span', {'class': 'a-offscreen'})\n",
        "            if product_price:\n",
        "                product_price = product_price.text.strip()\n",
        "            else:\n",
        "                product_price = \"N/A\"\n",
        "\n",
        "            rating = product.find('span', {'class': 'a-icon-alt'})\n",
        "            if rating:\n",
        "                rating = rating.text.split()[0]\n",
        "            else:\n",
        "                rating = \"N/A\"\n",
        "\n",
        "            num_reviews = product.find('span', {'class': 'a-size-base'}).text.split()[0]\n",
        "\n",
        "            data.append({\n",
        "                'Product URL': product_url,\n",
        "                'Product Name': product_name,\n",
        "                'Product Price': product_price,\n",
        "                'Rating': rating,\n",
        "                'Number of Reviews': num_reviews\n",
        "            })\n",
        "\n",
        "        time.sleep(2)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "base_url = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1\"\n",
        "num_pages_to_scrape = 20\n",
        "\n",
        "\n",
        "scraped_data = scrape_product_listing(base_url, num_pages_to_scrape)\n",
        "\n",
        "\n",
        "csv_filename = 'scraped_products.csv'\n",
        "csv_fields = ['Product URL', 'Product Name', 'Product Price', 'Rating', 'Number of Reviews']\n",
        "\n",
        "with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=csv_fields)\n",
        "    writer.writeheader()\n",
        "    for item in scraped_data:\n",
        "        writer.writerow(item)\n",
        "\n",
        "print(f\"Scraped data saved to {csv_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPmuPc0Ymuzw",
        "outputId": "42a9f8dd-a53d-4552-9f23-956948d213c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped data saved to scraped_products.csv\n"
          ]
        }
      ]
    }
  ]
}